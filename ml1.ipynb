{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar bibliotecas\n",
    "#!pip install -U scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression , Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score , f1_score, precision_score, recall_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import  GridSearchCV , train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler ,PolynomialFeatures,normalize\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dados/df2018_2022.csv\", sep=\",\")\n",
    "df[(df['temporada']<=2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising distribution of data\n",
    "\n",
    "scatter_matrix(df[['mandante_placar','visitante_placar']], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modificando o resultado para numerico\n",
    "#df.loc[(df['resultado']==\"V\"),'resultado'] = 1\n",
    "#df.loc[(df['resultado']==\"D\"),'resultado'] = 2\n",
    "#df.loc[(df['resultado']==\"E\"),'resultado'] = 3\n",
    "\n",
    "#df.loc[(df['mv']==\"m\"),'mandante'] = 1\n",
    "#df.loc[(df['mv']==\"v\"),'mandante'] = 0\n",
    "#df.loc[(df['mv']==\"v\"),'visitante'] = 1\n",
    "#df.loc[(df['mv']==\"m\"),'visitante'] = 0\n",
    "\n",
    "#df['mandante'] = df['mandante'].astype(int)\n",
    "#df['visitante'] = df['visitante'].astype(int)\n",
    "#df['resultado'] = df['resultado'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listando features categoricas e numéricas:\n",
    "categorical_attributes = list(df.select_dtypes(include=['object']).columns)\n",
    "numerical_attributes = list(df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "print('categorical_attributes:', categorical_attributes)\n",
    "print('numerical_attributes:', numerical_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deixar somente as variáveis numericas \n",
    "num_data  =df.drop(['partida_id','rodada','mandante', 'visitante', 'formacao_mandante', 'formacao_visitante', 'clube_mandante', 'clube_visitante'],axis=1)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa as features \n",
    "features = num_data.drop(['resultado'],axis=1)\n",
    "#separa as labels\n",
    "Y = num_data['resultado']\n",
    "\n",
    "\n",
    "print('Features')\n",
    "print (features.head())\n",
    "\n",
    "print (\" \")\n",
    "print ('#############')\n",
    "print (\" \")\n",
    "\n",
    "\n",
    "print ('Labels')\n",
    "print (Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escoolhendo as melhores features com Kbest\n",
    "\n",
    "features_list = ('mandante_placar','visitante_placar',\n",
    "                 'chutes_mandante','chutes_no_alvo_mandante','posse_de_bola_mandante',\n",
    "                 'passes_mandante','precisao_passes_mandante','faltas_mandante','cartao_amarelo_mandante',\n",
    "                 'cartao_vermelho_mandante','impedimentos_mandante','escanteios_mandante',\n",
    "                 'rodata_visitante','chutes_visitante','chutes_no_alvo_visitante','posse_de_bola_visitante',\n",
    "                 'passes_visitante','precisao_passes_visitante','faltas_visitante','cartao_amarelo_visitante',\n",
    "                 'cartao_vermelho_visitante','impedimentos_visitante','escanteios_visitante','temporada')\n",
    "\n",
    "k_best_features = SelectKBest(k='all')\n",
    "k_best_features.fit_transform(features, Y)\n",
    "k_best_features_scores = k_best_features.scores_\n",
    "raw_pairs = zip(features_list[1:], k_best_features_scores)\n",
    "ordered_pairs = list(reversed(sorted(raw_pairs, key=lambda x: x[1])))\n",
    "\n",
    "k_best_features_final = dict(ordered_pairs[:27])\n",
    "best_features = k_best_features_final.keys()\n",
    "print ('')\n",
    "print (\"Melhores features:\")\n",
    "print (k_best_features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa as features com base no Kbest\n",
    "features  = num_data.drop(['resultado','temporada', 'cartao_amarelo_visitante', 'impedimentos_visitante', 'precisao_passes_mandante', 'cartao_amarelo_mandante', 'chutes_no_alvo_visitante', 'cartao_vermelho_mandante', 'cartao_vermelho_visitante', 'escanteios_mandante', 'faltas_mandante', 'faltas_visitante', 'chutes_visitante', 'escanteios_visitante', 'chutes_no_alvo_mandante'],axis=1)\n",
    "\n",
    "print('Features')\n",
    "print (features.head())\n",
    "\n",
    "print ('=========')\n",
    "\n",
    "print ('Labels')\n",
    "print (Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devido ao OVERFITING, estou realizando um Low Variance Filter como tentativa de resolução\n",
    "#normalize = normalize(features) \n",
    "#data_scaled = pd.DataFrame(normalize)\n",
    "#data_scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the variance and name of variables\n",
    "#variance = data_scaled.var()\n",
    "#columns = features.columns\n",
    "\n",
    "#print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the names of variables having variance more than a threshold value\n",
    "\n",
    "#variable = [ ]\n",
    "\n",
    "#or i in range(0,len(variance)):\n",
    "#    if variance[i]>=0.0: #setting the threshold as 1%\n",
    "#        variable.append(columns[i-1])\n",
    "\n",
    "\n",
    "#variable\n",
    "\n",
    "#for i in range(0,len(variance)):\n",
    "#    print(variance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um novo dataframe usando as variáveis ​​acima\n",
    "#new_data = features[variable]\n",
    "\n",
    " # primeiras cinco linhas dos novos dados\n",
    "#new_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando os dados de entrada(features)\n",
    "scaler = MinMaxScaler().fit(features)\n",
    "X = scaler.transform(features)\n",
    "\n",
    "print ('Features: ',X.shape)\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a divisão dos dados de treine e teste e deixa do espaço 2650 a 3090 para validação do ml\n",
    "#X_train = features_scale[:2000 ]\n",
    "#X_test = features_scale[2000:2650]\n",
    "#y_train = labels[:2000]\n",
    "#y_test = labels[2000:2650]\n",
    "\n",
    "# Realiza a divisão de dados de treino e teste, separando 20% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "print( len(X_train), len(y_train))\n",
    "\n",
    "print( len(X_test), len(y_test))\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando e testando os modelos\n",
    "print ('LogisticRegression')\n",
    "\n",
    "clf_LR = LogisticRegression(multi_class='multinomial',max_iter=2000)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "pred= clf_LR.predict(X_train)\n",
    "\n",
    "lg_acc = accuracy_score(y_train, pred)\n",
    "f1=f1_score(y_train,pred,average = 'micro')\n",
    "print ('Acurácia LogisticRegression:{}'.format(lg_acc))\n",
    "print ('F1 Score:{}'.format(f1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testando LogistRegression hyper parameters\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "clf = search.best_estimator_\n",
    "pred= clf.predict(X_train)\n",
    "lg_acc = accuracy_score(y_train, pred)\n",
    "\n",
    "\n",
    "f1=f1_score(y_train,pred,average = 'macro')\n",
    "\n",
    "print ('Acurácia LogisticRegression:{}'.format(lg_acc))\n",
    "print ('F1 Score:{}'.format(f1) )\n",
    "\n",
    "print (clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando e testando os modelos\n",
    "print ('SVC')\n",
    "\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "pred= clf.predict(X_train)\n",
    "\n",
    "svc_acc = accuracy_score(y_train, pred)\n",
    "f1=f1_score(y_train,pred, average='micro')\n",
    "print ('Acurácia SVC:{}'.format(svc_acc))\n",
    "print ('F1 Score:{}'.format(f1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testando SVC hyper parameters\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "search = GridSearchCV(SVC(), param_grid)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "clf_SVC = search.best_estimator_\n",
    "pred= clf_SVC.predict(X_train)\n",
    "acc = accuracy_score(y_train, pred)\n",
    "\n",
    "\n",
    "f1=f1_score(y_train,pred,average = 'micro')\n",
    "\n",
    "print ('F1 Score:{}'.format(f1))\n",
    "\n",
    "print ('Acurácia LogisticRegression:{}'.format(acc))\n",
    "\n",
    "print(clf_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando e testando os modelos\n",
    "print ('Decision Tree')\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred= clf.predict(X_train)\n",
    "\n",
    "dt_acc = accuracy_score(y_train, pred)\n",
    "f1=f1_score(y_train,pred, average='macro')\n",
    "print ('Acurácia Tree:{}'.format(dt_acc))\n",
    "print ('F1 Score:{}'.format(f1) )\n",
    "\n",
    "\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [3, 10, 20, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando e testando os modelos\n",
    "print ('Naive baeys')\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred= clf.predict(X_train)\n",
    "\n",
    "nb_acc = accuracy_score(y_train, pred)\n",
    "f1=f1_score(y_train,pred, average='micro')\n",
    "print ('Acurácia Naive baeys:{}'.format(nb_acc))\n",
    "print ('F1 Score:{}'.format(f1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executando a previsao\n",
    "\n",
    "previsao=features_scale[2650:]\n",
    "\n",
    "game_id_full=df['partida_id']\n",
    "game_id=game_id_full[2650:]\n",
    "\n",
    "res_full=df['resultado']\n",
    "res=res_full[2650:]\n",
    "\n",
    "\n",
    "pred=clf_LR.predict(previsao)\n",
    "\n",
    "df=pd.DataFrame({'real': res, 'previsao':pred, 'partida_id':game_id})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion Matrix\n",
    "\n",
    "df=pd.DataFrame(df,columns=['real','previsao' ])\n",
    "\n",
    "cf_matrix=pd.crosstab(df['real'], df['previsao'], rownames=['real'] , colnames=['previsao'])\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relatório do modelo\n",
    "print('Relatório de classificação:\\n', classification_report(y_train, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for plotting\n",
    "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
    "    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n",
    "\n",
    "    plt.title(Title)\n",
    "    plt.xlabel('Price (in dollars)')\n",
    "    plt.ylabel('Proportion of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the distribution of the predicted values of the training data\n",
    "Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\n",
    "DistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Let's examine the distribution of the predicted values of the training data\n",
    "Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\n",
    "DistributionPlot(y_test, yhat_teste, \"Actual Values (teste)\", \"Predicted Values (teste)\", Title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
